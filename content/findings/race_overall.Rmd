---
title: "Race Relations"
output:
  html_document:
    toc: true
    toc_depth: 3
    number_sections: true
---

```{r setup, include=FALSE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = F, fig.width = 8,fig.height = 6)

library(stringi)
library(data.table)
library(tidyverse)
library(tidytext)
library(textstem)
library(readxl)
library(SnowballC)
library(rvest)
library(tm)
library(topicmodels)
library(tidyr)
library(textdata)
library(wordcloud)
library(RColorBrewer)
library(igraph)
library(ggraph)
library(widyr)
library(stringr)
library(networkD3)
library(RColorBrewer)
library(usmap)
library(viridis)
library(ggplot2)
library(BTM)
library(udpipe)
library(networkD3)
library(topicmodels)
library(igraph)
library(ggraph)
library(concaveman)
library(textplot)
library(stopwords)
library(dplyr)

data(stop_words)

collapse <- fread("~/git/dspg2020amsoldier/data/dictionary/collapse_words.csv", sep = ",")
collapse <- mutate(collapse, original = paste("\\b", original,"\\b", sep = "")) #so that stringr doesn't pick up on instances where it is part of another word
#replace with collapsed words
source(here::here("src", "load_data.R"))

data$long <- stri_replace_all_regex(data$long, collapse$original, collapse$collapse_union, vectorize_all = FALSE)
data$outfits_comment <- stri_replace_all_regex(data$outfits_comment, collapse$original, collapse$collapse_union, vectorize_all = FALSE)

S32N <- filter(data, racial_group == "black")
S32W <- filter(data, racial_group == "white")

text77_df <- tibble(row = 1:nrow(S32W), text = S32W$outfits_comment, outfits = S32W$outfits) #Written response to "should soldiers be in separate outfits?"
text78_df <- tibble(row = 1:nrow(S32W), text = S32W$long) #Written response on overall thoughts on the survey
textn_df <- tibble(row = 1:nrow(S32N), text = S32N$long)
```

# Introduction

Why we care about this topic and what we would like to learn

# Exploratory Data Analysis
```{r functions, include = F, echo=FALSE, message=FALSE, warning=FALSE}
# modifies the survey data to factor the multiple choice responses into interpretable variables
string ="01. US UNSPECIFIED 02. FOREIGN ALLY 11. MAINE 12. NEW HAMPSHIRE 13. VERMONT 14. MASSACHUSETTS 15. RHODE ISLAND 16. CONNECTICUT 21. NEW YORK 22. NEW JERSEY 23. PENNSYLVANIA 31. OHIO 32. INDIANA 33. ILLINOIS 34. MICHIGAN 35. WISCONSIN 41. MINNESOTA 42. IOWA 43. MISSOURI 44. NORTH DAKOTA 45. SOUTH DAKOTA 46. NEBRASKA 47. KANSAS 51. DELAWARE 52. MARYLAND 53. DC. 54. VIRGINIA 55. WEST VIRGINIA 56. NORTH CAROLINA 57. SOUTH CAROLINA 58. GEORGIA 59. FLORIDA 61. KENTUCKY 62. TENNESSEE 63. ALABAMA 64. MISSISSIPPI 71. ARKANSAS 72. LOUISIANA 73. OKLAHOMA 74. TEXAS 81. MONTANA 82. IDAHO 83. WYOMING 84. COLORADO 85. NEW MEXICO 86. ARIZONA 87. UTAH 88. NEVADA 91. WASHINGTON 92. OREGON 93. CALIFORNIA 00. NA"

state_codes = unlist(stri_extract_all_regex(string, "[:digit:]+"))
state = unlist(stri_extract_all_regex(string, "[:alpha:]+.[:alpha:]+|NA|DC"))

add_demographic_factors = function(df){
  if (length(df) == 130){
    df$age= factor(df$`Q.1.`,
                             levels = c(0:7),
                labels = c(NA, "<=19", "20", "21-24","25-27","28-29","30-34","35+"))
    df$edu = factor(df$`Q.2.`,
                 levels = c(0:10),
                 labels = c(NA,"< 4TH GRADE","4TH GRADE", "5TH GRADE", "6TH GRADE",
                            "7TH GRADE", "8TH GRADE", "SOME HIGH/TRADE SCHOOL",
                            "HIGH SCHOOL", "SOME COLLEGE",
                            "COLLEGE"))
    df$enlist = factor(df$`Q.3.`,
                 levels = c(0:3),
                 labels = c(NA, "DRAFTED","VOLUNTEERED", "NATIONAL GUARD"))
    df$post_war_rights = factor(df$Q.44.,
                            levels = c(0:4),
                            labels = c(NA, 'More Rights', 'Less Rights', 'Same Rights', 'Undecided' ))
    df$black_rights_should = factor(df$Q.58.,
                                levels = c(0:5),
                                labels = c(NA,"More","Less","No Change","Undecided",NA)) 
    df$black_rights_will = factor(df$Q.57.,
                             levels = c(0:5),
                             labels = c(NA,"More","Less","No Change","Undecided",NA))    
    df$outfits = factor(df$Q.63.,
                     levels = c( 0:5),
                     labels = c(NA , "Seperated", "Together",
                                "Doesn't Matter", "Undecided", NA))
    df$pxs = factor(df$Q.60.,
                levels = c(0:4),
                labels = c(NA, "Good Idea", "Bad Idea", "Undecided", NA))
    
    df$serviceclubs = factor(df$Q.62.,
                    levels = c(0:4),
                    labels = c(NA, "Good Idea", "Bad Idea", "Undecided", NA))    
    
    df$state = factor(df$Q.13.,
                   levels = state_codes,
                   labels = state)
    df$community = factor(df$Q.14.,
                       levels = c(0:5),
                       labels = c(NA,"Farm", "Small Town", "Town" ,"City", "Large City"))
  }
  else if (length(df) == 151){
    df$age= factor(df$R11,
                levels = c(0:7),
                labels = c(NA,"<=19", "20", "21-24","25-27","28-29","30-34","35+"))
    df$edu = factor(df$R12,
                 levels = c(0:10),
                 labels = c(NA, "< 4TH GRADE","4TH GRADE", "5TH GRADE", "6TH GRADE",
                            "7TH GRADE", "8TH GRADE", "SOME HIGH/TRADE SCHOOL",
                            "HIGH SCHOOL", "SOME COLLEGE",
                            "COLLEGE"))
    df$enlist = factor(df$R14,
                    levels = c(0:3),
                    labels = c(NA,"DRAFTED","VOLUNTEERED", "NATIONAL GUARD" ))
    df$post_war_rights = factor(df$R97,
                                levels = c(0:4),
                                labels = c(NA, 'More Rights', 'Less Rights', 'Same Rights', 'Undecided' ))
    df$black_treatment = factor(df$R104,
                                levels = c(0:5),
                                labels = c(NA, "Better", "Same", "Worse","Undecided",NA))
    df$black_rights_will = factor(df$R108,
                             levels = c(0:5),
                             labels = c(NA,"More","Less","No Change","Undecided",NA))
    df$outfits = factor(df$R134,
                     levels = c( 0:5),
                     labels = c("NA" , "Seperated", "Together",
                                "Doesn't Matter", "Undecided", NA))
    df$pxs = factor(df$R129,
                    levels = c(0:3),
                    labels = c(NA, "Good Idea", "Bad Idea", "Undecided"))
    df$serviceclubs = factor(df$R132,
                    levels = c(0:4),
                    labels = c(NA, "Good Idea", "Bad Idea", "Undecided", NA))
    df$state = factor(df$R47,
                   levels = state_codes,
                   labels = state)
    df$community = factor(df$R48,
                       levels = c(0:5),
                       labels = c(NA,"Farm", "Small Town", "Town" ,"City", "Large City"))
  }
  return(df)
}
```

```{r reading, include= F, echo=FALSE, message=FALSE, warning=FALSE}
w_ans = read_xlsx(here::here('data',"AMS032W_answers.xlsx")) %>% as.data.frame() %>% add_demographic_factors()
b_ans = read_xlsx(here::here('data',"AMS032N_answers.xlsx")) %>% as.data.frame() %>% add_demographic_factors()
w_ans$race = "White"; b_ans$race = "Black"
#tidifying the dataset
ans = w_ans[, (ncol(w_ans)-11):ncol(w_ans)] %>% full_join(b_ans[, (ncol(b_ans)-11):ncol(b_ans)])
my_cols = c("232d4b","2c4f6b","0e879c","60999a", "9bc0c0","d1e0bf", "ebf094", "d9e12b","e6ce3a","e6a01d","e57200","a35200","fdfdfd")
my_cols = paste0('#', my_cols)
```

## Who Are the Soldiers?

Survey 32 was given out to soldiers in 1943, approximately 5 years before the military was integrated. The survey was passed out to 7442 black soldiers and 4793 white soldiers and asked for basic demographic information, career aspirations, and more but of interests to us, Survey 32 asked the soldiers for their opinions on integration of military outfits. Our questions of interest are regarding age, education, enlistment, state, community type, and of course their opinions on outfits. On the survey these questions were asked in Questions 1,2,3,13,14, and 77 (63 for white soldiers), respectively. We also looked at questions regarding what their thoughts were about the future and how black rights and treatment will change after the war. 

### Age
Age was not collected on a continuous scale and was discretized into a few different age groups. We see that the overwhelming bulk of black soldiers who were survied were 20 years old with a small portion who were 19 or younger. In the meanwhile, the white soldiers had more spread to their ages with most soldiers being between the ages of 21 and 24. 

```{r, echo=FALSE, message=FALSE, warning=FALSE}
w_ans %>% 
  count(age, sort =T) %>% 
  na.omit() %>% 
  left_join(b_ans %>% count(age, sort =T) %>% na.omit(),by = "age") %>%
  melt(id.vars= "age") %>%
  ggplot(aes(fill=variable)) +
  geom_bar(aes(reorder(age,value),value), stat='identity', position='dodge')+
  labs(title='Age Groups of Soldiers', x="Age Groups", y = "Count")+
  scale_fill_manual(values =  c(my_cols[10], my_cols[4]), name = 'Race', labels = c("White", "Black"))
```

### Education
If we look at education now we see that again black soldiers have little spread in their education. Remarkably, all of the black soldiers survied have less than a 5th grade education at the time. Meanwhile, the bulk of the white soldiers have had a high school/some high school. 

```{r, echo=FALSE, message=FALSE, warning=FALSE}
w_ans %>% 
  count(edu, sort =T) %>% 
  na.omit() %>% 
  left_join(b_ans %>% count(edu, sort =T) %>% na.omit(),by = "edu") %>%
  melt(id.vars= "edu") %>%
  ggplot(aes(fill=variable)) +
  geom_bar(aes(reorder(edu,value),value), stat='identity', position='dodge')+
  labs(title='Education Levels of Soldiers', x="Education", y = "Count")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  scale_fill_manual(values =  c(my_cols[10], my_cols[4]), name = 'Race', labels = c("White", "Black"))
```

When we overlay the distribution of education levels with age ranges, we see that older white soldiers made up a larger porportion of white soldiers with less education compared to soldiers with some high school. As a contingent, it appears that soldiers between 21 and 24 with a high school education make up the largest contingent of white white soldiers when grouped by education and age. 

```{r, echo=FALSE, message=FALSE, warning=FALSE}
ans %>%
ggplot( aes(x=edu, fill = age)) +geom_bar(position= "fill") +
  facet_grid(rows = vars(race), scales="free_y")+
  labs(title="Age Distribution over Education Levels of Black Soldiers", x="Education Level", y = "Proportion")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  scale_fill_manual(values = rev(my_cols[1:7]))
```

### Enlistment
Something interesting arises here were we find that vast majority of the black soldiers actually volunteered to join the military whereas about 3/4 of the survied white soldiers were drafted and the remaining soldiers were mostly volunteers and a few were from the National Guard.
```{r, echo=FALSE, message=FALSE, warning=FALSE}
w_ans %>% 
  count(enlist, sort =T) %>% 
  na.omit() %>% 
  left_join(b_ans %>% count(enlist, sort =T) %>% na.omit(),by = "enlist") %>%
  melt(id.vars= "enlist") %>%
  ggplot(aes(fill=variable)) +
  geom_bar(aes(reorder(enlist,value),value), stat='identity', position='dodge')+
  labs(title='How Soldiers were Enlisted', x="Enlistment", y = "Count")+
  scale_fill_manual(values =  c(my_cols[10], my_cols[4]), name = 'Race', labels = c("White", "Black"))

```

### Location
Expectedly, most of the soldiers hailed from the most populous states at the time. White soldiers were mostly from Illionois, Pennsylvania, Ney York, Texas, and Michigan while black soldiers were mostly from Texas, New York, Illinois, Pennsylvania, and Ohio. Note that the top 4 states for white soldiers had similar amounts of soldiers but there was a sever drop off in representation of black soldiers from other states after Texas and New York.  

```{r, echo=FALSE, message=FALSE, warning=FALSE}
b_ans %>% 
  count(state, sort =T) %>% 
  na.omit() %>% 
  left_join(w_ans %>% count(state, sort =T) %>% na.omit(),by = "state") %>%
  melt(id.vars= "state") %>%
  ggplot() +
  geom_bar(aes(reorder(state,value),value, fill = variable), stat='identity', position='dodge')+
  facet_grid(cols = vars(variable))+
  scale_fill_manual(values =  c(my_cols[4], my_cols[10]), name = 'Race', labels = c("Black", "White"))+
  labs(title="Where are the Soldiers from", x="State", y = "Count") +
  coord_flip()+
  theme(strip.text.x = element_blank())

w_state <- w_ans %>%
  group_by(state) %>%
  summarise (n = n()) %>%
  mutate(freq = n / sum(n))
plot_usmap(data = w_state, values = "freq", regions = "state") + 
  labs(title = "Heat Map of Relative Frequency of White US Soldiers by State") + 
  scale_fill_continuous(low = "white", high = "red", name = "Frequency", label = scales::comma) +
  theme(legend.position = "right")
b_state <- b_ans %>%
  group_by(state) %>%
  summarise (n = n()) %>%
  mutate(freq = n / sum(n))
plot_usmap(data = b_state, values = "freq", regions = "state") + 
  labs(title = "Heat Map of Relative Frequency of Black US Soldiers by State") + 
  scale_fill_continuous(low = "white", high = "red", name = "Frequency", label = scales::comma) +
  theme(legend.position = "right")
```

### Communities
As expected, most soldiers whose home communities are large cities had the most representation across both groups. White soldiers saw roughly equal representation from soldiers who came from a farm, town, or city with actually slightly less people from cities. On the otherhand, the next community with the largest representation for black soldiers was a city followed by farms and towns which had approximately similar contributions. 

```{r, echo=FALSE, message=FALSE, warning=FALSE}
ans %>% group_by(race) %>% count(community) %>% na.omit() %>%
  ggplot() +
  geom_bar(aes(reorder(community,n),n, fill = race), stat='identity', position='dodge')+
  facet_grid(rows = vars(race))+
  labs(title='Community Type of Soldiers', x="Community", y = "Count")+
  scale_fill_manual(values =  c(my_cols[4], my_cols[10]), guide=FALSE)
```

We see that larger portions of soldiers who are more educated come from communities which are larger in population.

```{r, education+community, echo=FALSE, message=FALSE, warning=FALSE}
ans %>%
ggplot( aes(x=edu, fill = community)) +geom_bar(position= "fill") +
  facet_grid(rows = vars(race), scales="free_y")+
  labs(title="Community Distribution over Education Levels of Soldiers", x="Education Level", y = "Proportion")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  scale_fill_manual(values = rev(my_cols[1:7]))
```

### Integrating Outfits
Our key variable of interest from this survey is the soldiers opinions on integrating their outfits. Expectedly, we see the vast majority of white soldiers are against integrating however the black soldeirs seem to be divided on whether they want integration or not. They are rougly evenly split on keeping outfits seperated and integrating them and a good amount are also undecided or indifferent. 
```{r outfits, echo=FALSE, message=FALSE, warning=FALSE}
ans %>% filter(outfits!="NA") %>%
  ggplot(aes(x=outfits, fill = race)) +geom_bar(aes(y = ..prop.., group = 1)) +
  facet_grid(~race)+
  ggtitle("Soldiers' Opinions on Outfits")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  scale_fill_manual(values =  c(my_cols[4], my_cols[10]), guide=FALSE)
```

If we look at the proportion of ages who elected for each category we see that the proportions are relatively stable across all opinions towards integration.

```{r, outfits+age , echo=FALSE, message=FALSE, warning=FALSE}
ans %>% filter(outfits!="NA") %>%
ggplot( aes(x=outfits, fill = age)) +geom_bar(position= "fill") +
  facet_grid(rows = vars(race), scales="free_y")+
  labs(title="Age Distribution over Integration of Outfits Opinions", x="Opinion", y = "Proportion")+
  scale_fill_manual(values = rev(my_cols[1:7]))
```

Now if we are to overlay the education distribution over the integration opinions we see something more interesting. It appears that the white soldiers that voted for the outfits to be together skew towards being more educated. In fact, over 50% of the soldiers who did vote for integrated units have atleast finished high school. This is not the case for any of the other responses. 

```{r, outfits + edu, echo=FALSE, message=FALSE, warning=FALSE}


ans %>% filter(outfits!="NA") %>%
ggplot( aes(x=outfits, fill = edu)) +geom_bar(position= "fill") +
  facet_grid(rows = vars(race), scales="free_y")+
  labs(title="Education Distribution over Integration of Outfits Opinions", x="Opinion", y = "Proportion")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  scale_fill_manual(values = rev(my_cols[1:10]))
```

Across both races we also see that of those who choose integration a greater portion were from large cities and soldiers who came from more populated voted for sepration less proportionally. 

```{r, echo=FALSE, message=FALSE, warning=FALSE}
ans %>% filter(outfits!="NA") %>%
ggplot( aes(x=outfits, fill = community)) +geom_bar(position= "fill") +
  facet_grid(rows = vars(race), scales="free_y")+
  labs(title="Community Type Distribution over Integration of Outfits Opinions", x="Opinion", y = "Proportion")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  scale_fill_manual(values = rev(my_cols[1:5]))
```

### Thoughts on the future
The majority of the white soldiers believed that their rights will not change after the war and roughly equal amoutns thought they would increase or decrease. About 40% of the black soldiers thought their rights would increase following the war. A slightly smaller amount expected no change at all. Interestingly, the black soldiers answers to whether black people will have more rights after the war was nearly identical, but now there are more white soldiers who think black people will get more rights. The majority of black soldiers thought that after the war white people would treat them the same but about 30% were optimistic that they'd recieve better treatment. Interestingly,

```{r, echo=FALSE, message=FALSE, warning=FALSE}
ans %>% 
  ggplot(aes(x=post_war_rights, fill = race)) +geom_bar(aes(y = ..prop.., group = 1)) +
  facet_grid(~race)+
  ggtitle("Soldiers' Opinions on If They Will Have More Rights After the War")+
  scale_fill_manual(values = c(my_cols[4], my_cols[10]), name = 'Race', guide = F)+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  labs(x="Rights After the War", y = "Prop") 

ans %>% 
  ggplot(aes(x=black_rights_will, fill = race)) +geom_bar(aes(y = ..prop.., group = 1)) +
  facet_grid(~race)+
  ggtitle("Soldiers' Opinions on If Blacks Will Have More Rights After the War")+
  scale_fill_manual(values = c(my_cols[4], my_cols[10]), name = 'Race', guide = F)+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  labs(x="Rights After the War", y = "Prop") 

b_ans %>%
  ggplot(aes(black_treatment))+
  geom_bar(aes(y = ..prop.., group = 1), fill = my_cols[4])+
  labs(x="Treatment by White People", y = "Prop", title = 'Black Soldiers Opinions on Post-War Treatment by White People ') 
```





## Differences in Sets - Non-Stemmed

## Differences in Sets - Stemmed
When we are completing analysis on two different groups of people's textual data something we have been curious about is the unique words each group uses. So, for example, there are terms black soldiers use that white soldiers do not and what is the frequency of those words. In the following section we report differences in unique words and their frequencies in long responses and in short responses across our four samples of interest: black soldiers, white soldiers, pro-segregation white soldiers, and anti-segregation white soldiers.

### Long Responses
The following sub-section reports differences across black and white soldiers' long responses. We include word clouds to better visualize unique terms.

```{r stem sets, echo=FALSE, message=FALSE, warning=FALSE}
word_counts <- s32 %>%
  filter(response_type == "long") %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words) %>%
  mutate(word = wordStem(word)) %>%
  group_by(racial_group, response_type, word) %>%
  count() %>%
  arrange(desc(n))

black_words <- word_counts %>% filter(racial_group == "black")
white_words <- word_counts %>% filter(racial_group == "white")
unique_black_words <- anti_join(black_words, white_words, by = "word")
unique_white_words <- anti_join(white_words, black_words, by = "word")

word_totals <- word_counts %>%
  group_by(racial_group) %>%
  summarize(sum = sum(n))

word_props <- word_counts %>%
  inner_join(word_totals) %>%
  mutate(prop = n / sum) %>%
  arrange(desc(prop))

black_props <- word_props %>%
  ungroup() %>%
  filter(racial_group == "black") %>%
  rename(black_prop = prop) %>%
  select(c("word", "black_prop"))

white_props <- word_props %>%
  ungroup() %>%
  filter(racial_group == "white") %>%
  rename(white_prop = prop) %>%
  select(c("word", "white_prop"))

word_props_joined <- full_join(black_props, white_props, by = "word") %>%
  replace_na(replace = list(black_props = 0, white_props = 0))

word_props_joined$rel_prop <- abs(word_props_joined$black_prop - word_props_joined$white_prop)
word_props_final <- word_props_joined %>% arrange(desc(rel_prop))

# unique word frequency plots

unique_black_words %>%
  as.data.frame(.) %>%
  arrange(desc(n)) %>%
  mutate(word = factor(word, levels = word)) %>%
  top_n(10, n) %>%
  ggplot(., aes(x = word, y = n)) +
  geom_bar(stat = "identity", fill = "lightblue") +
  labs(title = "Frequency of Unique Words in Black Soldiers' Long Responses",
       x = "Word",
       y = "Frequency") +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
  coord_flip()

unique_white_words %>%
  as.data.frame(.) %>%
  arrange(desc(n)) %>%
  mutate(word = factor(word, levels = word)) %>%
  top_n(10, n) %>%
  ggplot(., aes(x = word, y = n)) +
  geom_bar(stat = "identity", fill = "lightblue") +
  labs(title = "Frequency of Unique Words in White Soldiers' Long Responses",
       x = "Word",
       y = "Frequency") +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
  coord_flip()

# word clouds
white_props %>%
  with(wordcloud(word, white_prop, max.words = 20))

black_props %>%
  with(wordcloud(word, black_prop, max.words = 20))
```

### Short Responses
The following sub-section reports differences across pro-segregation and anti-segregation white soldiers' short responses. We include word clouds to better visualize unique terms.

```{r stemmed seg int, echo = FALSE, message=FALSE, warning=FALSE}
word_counts_short <- s32 %>%
  filter(response_type == "short") %>%
  unnest_tokens(word, text) %>%
  anti_join(stop_words) %>%
  mutate(word = wordStem(word)) %>%
  group_by(racial_group, response_type, word, outfits) %>%
  filter(outfits == "['They should be in separate outfits']" | outfits == "['They should be together in the same outfits']") %>%
  count() %>%
  arrange(desc(n))

seg_words <- word_counts_short %>% filter(outfits == "['They should be in separate outfits']")
int_words <- word_counts_short %>% filter(outfits == "['They should be together in the same outfits']")
unique_seg_words <- anti_join(seg_words, int_words, by = "word")
unique_int_words <- anti_join(int_words, seg_words, by = "word")

word_totals_short <- word_counts_short %>%
  group_by(outfits) %>%
  summarize(sum = sum(n))

word_props_short <- word_counts_short %>%
  inner_join(word_totals_short) %>%
  mutate(prop = n / sum) %>%
  arrange(desc(prop))

seg_props <- word_props_short %>%
  ungroup() %>%
  filter(outfits == "['They should be in separate outfits']") %>%
  rename(seg_prop = prop) %>%
  select(c("word", "seg_prop"))

int_props <- word_props_short %>%
  ungroup() %>%
  filter(outfits == "['They should be together in the same outfits']") %>%
  rename(int_prop = prop) %>%
  select(c("word", "int_prop"))

word_props_short_joined <- full_join(seg_props, int_props, by = "word") %>%
  replace_na(replace = list(seg_props = 0, int_props = 0))

word_props_short_joined$rel_prop <- abs(word_props_short_joined$seg_prop - word_props_short_joined$int_prop)
word_props_final_short <- word_props_short_joined %>% arrange(desc(rel_prop))

# unique word frequency plots

unique_seg_words %>%
  as.data.frame(.) %>%
  arrange(desc(n)) %>%
  mutate(word = factor(word, levels = word)) %>%
  top_n(10, n) %>%
  ggplot(., aes(x = word, y = n)) +
  geom_bar(stat = "identity", fill = "lightblue") +
  labs(title = "Frequency of Unique Words in Pro-Segregation White Soldiers' Short Responses",
       x = "Word",
       y = "Frequency") +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
  coord_flip()

unique_int_words %>%
  as.data.frame(.) %>%
  arrange(desc(n)) %>%
  mutate(word = factor(word, levels = word)) %>%
  top_n(4, n) %>%
  ggplot(., aes(x = word, y = n)) +
  geom_bar(stat = "identity", fill = "lightblue") +
  labs(title = "Frequency of Unique Words in Anti-Segregation White Soldiers' Short Responses",
       x = "Word",
       y = "Frequency") +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
  coord_flip()

# word clouds
seg_props %>%
  with(wordcloud(word, seg_prop, max.words = 20))

int_props %>%
  with(wordcloud(word, int_prop, max.words = 20))
```

# Sentiment Analysis

```{r sent, echo=FALSE, message=FALSE, warning=FALSE}

```

## Differences in Sets


# Social Network Analysis

```{r sna, echo=FALSE, message=FALSE, warning=FALSE}

```

## Social Networks with Unionized Terminology
Something that is important to us is soldiers' dicussions of inner-outer groups of people. A way that we decided to look at that was by unionizing biterms. For example, a naive co-occurence with "black" may be "people" but we care about the dicussion of "black people" rather than just the identification of "people" as co-occurring with the word "black". To do this we complete several unionizations of biterms to create co-occurrence networks of dicussions of groups of people.

### Long Responses
We complete unionized term co-occurences and social networks using long response textual data. We separate our analysis by race and report co-occurences and co-occurence networks for both black and white soldiers.

```{r unions, echo = FALSE, message=FALSE, warning=FALSE}
row_n_words <- textn_df %>%
  mutate(section = row_number()) %>%
  filter(section > 0) %>%
  unnest_tokens(word, text) %>%
  filter(!word %in% stop_words$word) %>%
  mutate(word= textstem::lemmatize_words(word)) %>%
  mutate(word= wordStem(word))

# count words co-occuring within sections
word_pairs_n <- row_n_words %>%
  pairwise_count(word, section, sort = TRUE)

word_cors_n <- row_n_words %>%
  group_by(word) %>%
  filter(n() >= 20) %>%
  pairwise_cor(word, section, sort = TRUE) %>%
  filter(correlation > .1)
# write.csv(word_cors_n, "clean_black_long_edge_occur.csv")
#visualizes correlation network
# word_cors_n %>%
#   simpleNetwork(fontSize = 12, zoom =T)

# colorman, whiteman, coloredsoldi, negrosoldi, whitesoldi
word_cors_n %>%
  filter(item1 %in% c("blackmal", "whitemal")) %>%
  group_by(item1) %>%
  filter(item2 != "blackmal") %>%
  filter(item2 != "whitemal") %>%
  filter(item2 != "negro") %>%
  filter(item2 != "white") %>%
  filter(item2 != "color") %>%
  filter(item2 != "south") %>%
  filter(item2 != "southern") %>%
  top_n(6) %>%
  ungroup() %>%
  mutate(item2 = reorder(item2, correlation)) %>%
  mutate(item1 = reorder(item1, correlation)) %>%
  ggplot(aes(item2, correlation)) +
  geom_bar(stat = "identity", fill = "#E57200") +
  xlab("Co-Occurring Word") +
  facet_wrap(~ item1, scales = "free") +
  ggtitle("Co-Occurences with Terms for Black Males and White Males \nfrom Black Soldiers' Long Responses") +
  coord_flip() +
  theme_minimal()

set.seed(2016)
word_cors_n %>%
  filter(correlation > .2) %>%
  graph_from_data_frame() %>%
  ggraph(layout = "fr") +
  geom_edge_link(aes(edge_alpha = correlation), show.legend = TRUE) +
  geom_node_point(color = "#E57200", size = 5) +
  geom_node_text(aes(label = name), repel = TRUE) +
  ggtitle("Co-Occurences of Words from Black Soldiers' Long \nResponses at the 15 percent Threshold") +
  theme_void()

# white long response
row_78_words <- text78_df %>%
  mutate(section = row_number()) %>%
  filter(section > 0) %>%
  unnest_tokens(word, text) %>%
  filter(!word %in% stop_words$word) %>%
  mutate(word= textstem::lemmatize_words(word)) %>%
  mutate(word= wordStem(word))

word_pairs_78 <- row_78_words %>%
  pairwise_count(word, section, sort = TRUE)

word_cors_78 <- row_78_words %>%
  group_by(word) %>%
  filter(n() >= 20) %>%
  pairwise_cor(word, section, sort = TRUE) %>%
  filter(correlation > .1)
# write.csv(word_cors_78, "clean_white_long_edge_occur.csv")
#visualizes correlation network
# word_cors_78 %>%
#   simpleNetwork(fontSize = 12, zoom =T)

# whiteman,

word_cors_78 %>%
  filter(item1 %in% c("whitemal", "blackmal")) %>%
  group_by(item1) %>%
  filter(item2 != "blackmal") %>%
  filter(item2 != "whitemal") %>%
  filter(item2 != "negro") %>%
  filter(item2 != "white") %>%
  filter(item2 != "color") %>%
  filter(item2 != "south") %>%
  filter(item2 != "southern") %>%
  top_n(6) %>%
  ungroup() %>%
  mutate(item2 = reorder(item2, correlation)) %>%
  mutate(item1 = reorder(item1, correlation)) %>%
  ggplot(aes(item2, correlation)) +
  geom_bar(stat = "identity", fill = "#2C4F6B") +
  xlab("Co-Occurring Word") +
  facet_wrap(~ item1, scales = "free") +
  ggtitle("Co-Occurences with Terms for Black Males and White Males \nfrom White Soldiers' Long Responses") +
  coord_flip() +
  theme_minimal()

set.seed(2016)
word_cors_78 %>%
  filter(correlation > .2) %>%
  graph_from_data_frame() %>%
  ggraph(layout = "fr") +
  geom_edge_link(aes(edge_alpha = correlation), show.legend = TRUE) +
  geom_node_point(color = "#2C4F6B", size = 5) +
  geom_node_text(aes(label = name), repel = TRUE) +
  ggtitle("Co-Occurences of Words from White Soldiers' Long \nResponses at the 15 percent Threshold") +
  theme_void()
```

### Short Responses

We complete the same unionized-analysis above but using only short-response data from white soldiers. We are unable to get enough data to create plots for the two different groups of white soldiers: pro-segregation and anti-segregation. The following analysis reflects terms used in the entire group of white soldiers.

```{r short, echo = FALSE, message=FALSE, warning=FALSE}

# for v against -------------------------------------------
# white for seg (w4)

# row_w4_words <- text77_df %>%
#   filter(outfits == "['They should be in separate outfits']") %>%
#   mutate(section = row_number()) %>%
#   filter(section > 0) %>%
#   unnest_tokens(word, text) %>%
#   filter(!word %in% stop_words$word) %>%
#   mutate(word= textstem::lemmatize_words(word)) %>%
#   mutate(word= wordStem(word))
# 
# word_pairs_w4 <- row_w4_words %>%
#   pairwise_count(word, section, sort = TRUE)
# 
# word_cors_w4 <- row_w4_words %>%
#   group_by(word) %>%
#   filter(n() >= 20) %>%
#   pairwise_cor(word, section, sort = TRUE)  %>%
#   filter(correlation > 0)
# #visualizes correlation network
# # word_cors_w4 %>%
# #   simpleNetwork(fontSize = 12, zoom =T)
# 
# # whiteman, negrosoldi
# word_cors_w4 %>%
#   filter(item1 %in% c("whitemal", "blackmal")) %>%
#   group_by(item1) %>%
#   filter(item2 != "blackmal") %>%
#   filter(item2 != "whitemal") %>%
#   filter(item2 != "negro") %>%
#   filter(item2 != "white") %>%
#   filter(item2 != "color") %>%
#   filter(item2 != "south") %>%
#   filter(item2 != "southern") %>%
#   top_n(6) %>%
#   ungroup() %>%
#   mutate(item2 = reorder(item2, correlation)) %>%
#   mutate(item1 = reorder(item1, correlation)) %>%
#   ggplot(aes(item2, correlation)) +
#   geom_bar(stat = "identity", fill = "#0E879C") +
#   xlab("Co-Occurring Word") +
#   facet_wrap(~ item1, scales = "free") +
#   ggtitle("Co-Occurences with 'Negro' and 'White' from Pro-segregation White Soldier's Short Comments") +
#   coord_flip()  +
#   theme_minimal()
# 
# set.seed(2016)
# word_cors_w4 %>%
#   filter(correlation > .15) %>%
#   graph_from_data_frame() %>%
#   ggraph(layout = "fr") +
#   geom_edge_link(aes(edge_alpha = correlation), show.legend = TRUE) +
#   geom_node_point(color = "#2C4F6B", size = 5) +
#   geom_node_text(aes(label = name), repel = TRUE) +
#   ggtitle("Co-Occurences of Words from White Soldiers' Pro-Segregation \nShort Responses at the 15 percent Threshold") +
#   theme_void()
# 
# # white against segregation (wag)
# row_wag_words <- text77_df %>%
#   filter(outfits == "['They should be together in the same outfits']") %>%
#   mutate(section = row_number()) %>%
#   filter(section > 0) %>%
#   unnest_tokens(word, text) %>%
#   filter(!word %in% stop_words$word) %>%
#   mutate(word= textstem::lemmatize_words(word)) %>%
#   mutate(word= wordStem(word))
# 
# word_pairs_wag <- row_wag_words %>%
#   pairwise_count(word, section, sort = TRUE)
# 
# word_cors_wag <- row_wag_words %>%
#   group_by(word) %>%
#   filter(n() >= 5) %>%
#   pairwise_cor(word, section, sort = TRUE) %>%
#   filter(correlation > 0)
# #visualizes correlation network
# # word_cors_wag %>%
# #   simpleNetwork(fontSize = 12, zoom =T)
# 
# # there arent any combos
# 
# word_cors_wag %>%
#   filter(item1 %in% c("whitemal", "blackmal")) %>%
#   group_by(item1) %>%
#   # filter(item2 != "blackmal") %>%
#   # filter(item2 != "whitemal") %>%
#   # filter(item2 != "negro") %>%
#   # filter(item2 != "white") %>%
#   # filter(item2 != "color") %>%
#   # filter(item2 != "south") %>%
#   # filter(item2 != "southern") %>%
#   top_n(6) %>%
#   ungroup() %>%
#   mutate(item2 = reorder(item2, correlation)) %>%
#   mutate(item1 = reorder(item1, correlation)) %>%
#   ggplot(aes(item2, correlation)) +
#   geom_bar(stat = "identity", fill = "#E6CE3A") +
#   xlab("Co-Occurring Word") +
#   facet_wrap(~ item1, scales = "free") +
#   ggtitle("Co-Occurences with 'Negro' and 'White' from Anti-segregation White Soldier's Short Comments") +
#   coord_flip()  +
#   theme_minimal()
# 
# set.seed(2016)
# word_cors_wag %>%
#   filter(correlation > .15) %>%
#   graph_from_data_frame() %>%
#   ggraph(layout = "fr") +
#   geom_edge_link(aes(edge_alpha = correlation), show.legend = TRUE) +
#   geom_node_point(color = "#E57200", size = 5) +
#   geom_node_text(aes(label = name), repel = TRUE) +
#   ggtitle("Co-Occurences of Words from Anti-Segregation White Soldiers' Short Responses at the 15 percent Threshold") +
#   theme_void()

row_77_words <- text77_df %>%
  mutate(section = row_number()) %>%
  filter(section > 0) %>%
  unnest_tokens(word, text) %>%
  filter(!word %in% stop_words$word) %>%
  mutate(word= textstem::lemmatize_words(word)) %>%
  mutate(word= wordStem(word))

word_pairs_77 <- row_77_words %>%
  pairwise_count(word, section, sort = TRUE)

word_cors_77 <- row_77_words %>%
  group_by(word) %>%
  filter(n() >= 5) %>%
  pairwise_cor(word, section, sort = TRUE)
# write.csv(word_cors_77, "clean_white_short_occur.csv")
#visualizes correlation network
# word_cors_77 %>%
#   simpleNetwork(fontSize = 12, zoom =T)

word_cors_77 %>%
  filter(item1 %in% c("blackmal", "whitemal")) %>%
  group_by(item1) %>%
  filter(item2 != "blackmal") %>%
  filter(item2 != "whitemal") %>%
  filter(item2 != "negro") %>%
  filter(item2 != "white") %>%
  filter(item2 != "color") %>%
  filter(item2 != "south") %>%
  filter(item2 != "southern") %>%
  top_n(6) %>%
  ungroup() %>%
  mutate(item2 = reorder(item2, correlation)) %>%
  mutate(item1 = reorder(item1, correlation)) %>%
  ggplot(aes(item2, correlation)) +
  geom_bar(stat = "identity", fill = "#E6CE3A") +
  xlab("Co-Occurring Word") +
  facet_wrap(~ item1, scales = "free") +
  ggtitle("Co-Occurences with 'Negro' and 'White' from White Soldier's Short Comments") +
  coord_flip()  +
  theme_minimal()

set.seed(2016)
word_cors_77 %>%
  filter(correlation > .15) %>%
  graph_from_data_frame() %>%
  ggraph(layout = "fr") +
  geom_edge_link(aes(edge_alpha = correlation), show.legend = TRUE) +
  geom_node_point(color = "#E6CE3A", size = 5) +
  geom_node_text(aes(label = name), repel = TRUE) +
  ggtitle("Co-Occurences of Words from White Soldiers' Short \nResponses at the 15 percent Threshold") +
  theme_minimal()
```

## Identifying Topics

```{r, include = FALSE, echo = FALSE, message=FALSE, warning=FALSE}
tidy_topic_probs = function(model){
  df <- cbind(source = rownames(model$phi), model$phi)
  rownames(df) <- 1:nrow(df)
  df = as.data.frame(df)
  edge_list = reshape2::melt(df, id.vars=c("source"), variable.name = "target", value.name = "weight")
}

biterms_n = read.csv(here::here("data","biterms_n.csv"))
biterms_77 = read.csv(here::here("data","biterms_77.csv"))
biterms_78 = read.csv(here::here("data","biterms_78.csv"))

traindata_n = read.csv(here::here("data","traindata_n.csv"))
traindata_77 = read.csv(here::here("data","traindata_77.csv"))
traindata_78 = read.csv(here::here("data","traindata_78.csv"))

row.names(traindata_n) <- traindata_n$X
row.names(traindata_77) <- traindata_77$X
row.names(traindata_78) <- traindata_78$X

```


```{r lda, include = FALSE, echo = FALSE, message=FALSE, warning=FALSE}
text77_df <- tibble(row = 1:nrow(S32W), text = S32W$outfits_comment, outfits = S32W$outfits) #Written response to "should soldiers be in separate outfits?"
text78_df <- tibble(row = 1:nrow(S32W), text = S32W$long) #Written response on overall thoughts on the survey
textn_df <- tibble(row = 1:nrow(S32N), text = S32N$long) #Written response to "should soldiers be in separate outfits?"

# laod in stop words: words without any true meaning
data(stop_words)

# Bunch of useless one word responses
useless_responses = c("none","None","0", "12","none.","[none]","noone","[blank]","gujfujuj", "None.", "I", NA)

tidy_77 <- text77_df %>%
  filter(!text %in% useless_responses) %>% #filtering out useless 1 word responses
  unnest_tokens(word, text) %>%
  anti_join(stop_words) %>%
  mutate(word = wordStem(word)) %>%
  group_by(row) %>%
  dplyr::count(word, sort = T) %>%
  mutate(response = "short", race = "white")

tidy_78 <- text78_df %>%
  filter(!text %in% useless_responses) %>% #filtering out useless 1 word responses
  unnest_tokens(word, text) %>%
  anti_join(stop_words) %>%
  mutate(word = wordStem(word)) %>%
  group_by(row) %>%
  dplyr::count(word, sort = T) %>%
  mutate(response = "long", race = "white")

tidy_n <- textn_df %>%
  filter(!text %in% useless_responses) %>% #filtering out useless 1 word responses
  unnest_tokens(word, text) %>%
  anti_join(stop_words) %>%
  mutate(word = wordStem(word)) %>%
  group_by(row) %>%
  dplyr::count(word, sort = T) %>%
  mutate(response = "long", race = "black")


# lda ---------------------------------------------------------------
# LDA finds topics depending on the number of clusters you want
# number of clusters we want

dtm_77 <- cast_dtm(tidy_77, term = word, document = row, value = n)
dtm_78 <- cast_dtm(tidy_78, term = word, document = row, value = n)
dtm_n <- cast_dtm(tidy_n, term = word, document = row, value = n)

num_clusters <- 6
weight_strength = .01
lda_77 <- LDA(dtm_77, k = num_clusters, method = "Gibbs", control = NULL)
lda_78 <- LDA(dtm_78, k = num_clusters, method = "Gibbs", control = NULL)
lda_n <- LDA(dtm_n, k = num_clusters, method = "Gibbs", control = NULL)

# this will separate out topics and have a weighted probability
topics_77_lda <- tidy(lda_77, matrix = "beta")
topics_78_lda <- tidy(lda_78, matrix = "beta")
topics_n_lda <- tidy(lda_n, matrix = "beta")

#takes word topic betas and graphs them as a network
colnames(topics_n_lda) = colnames(topics_77_lda) = colnames(topics_78_lda) =  c("source", "target", "weight")
```

## Topic Model Networks

A topic model put simply models the topics in a piece of text and the words that are associated with each topic. Naturally, words may fall in multiple topics and the model accounts for this by giving each topic a probability distribution over the words. A Topic Model Network is a useful way to visualize the topics and the words associated with each topic. Here we will explore two different topic models.

### Latent Dirichlet Allocation

Latent Dirchlet Allocation, or LDA, is the typical go to method for topic modelling. We chose to model the texts with 6 topics. We can see that in the three networks this produces very disconnected topics which intuitively seems to be a poor fit as the corpus is rather small and the soldiers are responding to direct and specific questions. LDA does produce a better connected network for the white soldiers outfits comment but does not do a great job in delineating the topics.

#### Black Soldiers Long Comment
```{r black lda, echo = F, echo = FALSE, message=FALSE, warning=FALSE}
edgelist_n_lda= topics_n_lda %>%
  filter(weight >= .01) %>%
  arrange(target)

sources <- paste("Topic", edgelist_n_lda$source)
targets <- edgelist_n_lda$target
node_names <- factor(unique(c(sort(unique(sources)), as.character(targets))))



groups = edgelist_n_lda %>% group_by(target) %>% top_n(1, weight)
groups = groups$source
nodes <- data.frame(name = node_names, group = c(1:num_clusters, groups), size = 8)
links <- data.frame(source = match(sources, node_names) - 1, 
                    target = match(targets, node_names) - 1, 
                    value = edgelist_n_lda$weight)
net_n_lda = forceNetwork(Links = links, Nodes = nodes, Source = "source",
             Target = "target", Value = "value", NodeID = "name",
             Group = "group", opacity = 0.9, zoom = T)
net_n_lda
```

#### White Soldiers Outfits Comment
```{r 77 lda, echo = F, echo = FALSE, message=FALSE, warning=FALSE}
edgelist_77_lda= topics_77_lda %>%
  filter(weight >= .01) %>%
  arrange(target)

sources <- paste("Topic", edgelist_77_lda$source)
targets <- edgelist_77_lda$target
node_names <- factor(unique(c(sort(unique(sources)), as.character(targets))))



groups = edgelist_77_lda %>% group_by(target) %>% top_n(1, weight)
groups = groups$source
nodes <- data.frame(name = node_names, group = c(1:num_clusters, groups), size = 8)
links <- data.frame(source = match(sources, node_names) - 1, 
                    target = match(targets, node_names) - 1, 
                    value = edgelist_77_lda$weight)
net_77_lda = forceNetwork(Links = links, Nodes = nodes, Source = "source",
             Target = "target", Value = "value", NodeID = "name",
             Group = "group", opacity = 0.9, zoom = T)
net_77_lda
```

#### White Soldiers Long Comment
```{r 78 lda, echo=F, echo = FALSE, message=FALSE, warning=FALSE}
edgelist_78_lda= topics_78_lda %>%
  filter(weight >= .01) %>%
  arrange(target)

sources <- paste("Topic", edgelist_78_lda$source)
targets <- edgelist_78_lda$target
node_names <- factor(unique(c(sort(unique(sources)), as.character(targets))))



groups = edgelist_78_lda %>% group_by(target) %>% top_n(1, weight)
groups = groups$source
nodes <- data.frame(name = node_names, group = c(1:num_clusters, groups), size = 8)
links <- data.frame(source = match(sources, node_names) - 1, 
                    target = match(targets, node_names) - 1, 
                    value = edgelist_78_lda$weight)
net_78_lda = forceNetwork(Links = links, Nodes = nodes, Source = "source",
             Target = "target", Value = "value", NodeID = "name",
             Group = "group", opacity = 0.9, zoom = T)
net_78_lda
```

### BTM

There are some drawbacks to using LDA for our dataset, namely it doesn't handle short texts well. That is why we also implemented a [Biterm Topic Model](https://cran.r-project.org/web/packages/BTM/index.html) that does better on short texts. Overall, it seems that the topic model networks produced this way strike a better balance between effectively delineating the topics and showing interconnectivity. 
```{r btm, include = FALSE, echo = FALSE, message=FALSE, warning=FALSE}

K = 6
modeln      <- BTM(traindata_n[-1], biterms = biterms_n[-1], k = K, iter = 2000, background = TRUE, trace = 100)
model77     <- BTM(traindata_77[-1], biterms = biterms_77[-1], k = K, iter = 2000, background = TRUE, trace = 100)
model78     <- BTM(traindata_78[-1], biterms = biterms_78[-1], k = K, iter = 2000, background = TRUE, trace = 100)
```

```{r, include = FALSE, echo = FALSE, message=FALSE, warning=FALSE}
library(plyr)

V = c("V2","V3", "V4", "V5", "V6", "V7", "V8", "V9", "V10")
topics = c("Topic 1","Topic 2", "Topic 3", "Topic 4", "Topic 5", "Topic 6", "Topic 7", "Topic 8", "Topic 9")

topics_n_btm = tidy_topic_probs(modeln)
topics_n_btm$weight = as.numeric(topics_n_btm$weight)
topics_n_btm$target = topics_n_btm$target %>%
  mapvalues(from = V, to = topics)
topics_n_btm = topics_n_btm[, c(2, 1, 3)]

topics_77_btm = tidy_topic_probs(model77)
topics_77_btm$weight = as.numeric(topics_77_btm$weight)
topics_77_btm$target = topics_77_btm$target %>%
  mapvalues(from = V, to = topics)
topics_77_btm = topics_77_btm[, c(2, 1, 3)]

topics_78_btm = tidy_topic_probs(model78)
topics_78_btm$weight = as.numeric(topics_78_btm$weight)
topics_78_btm$target = topics_78_btm$target %>%
  mapvalues(from = V, to = topics)
topics_78_btm = topics_78_btm[, c(2, 1, 3)]


colnames(topics_n_btm) = colnames(topics_77_btm) = colnames(topics_78_btm) =  c("source", "target", "weight")
```

#### Black Soldiers Long Comment
```{r black btm, echo = F, echo = FALSE, message=FALSE, warning=FALSE}
edgelist_n_btm= topics_n_btm %>%
  filter(weight >= .01) %>%
  arrange(target)

sources <- edgelist_n_btm$source
targets <- edgelist_n_btm$target
node_names <- factor(unique(c(sort(unique(as.character(sources))), as.character(targets))))



groups = edgelist_n_btm %>% group_by(target) %>% top_n(1, weight)
groups = groups$source
nodes <- data.frame(name = node_names, group = c(1:num_clusters, groups), size = 8)
links <- data.frame(source = match(sources, node_names) - 1, 
                    target = match(targets, node_names) - 1, 
                    value = edgelist_n_btm$weight)
net_n_btm = forceNetwork(Links = links, Nodes = nodes, Source = "source",
             Target = "target", Value = "value", NodeID = "name",
             Group = "group", opacity = 0.9, zoom = T)
net_n_btm
```

#### White Soldiers Outfits Comment
```{r 77 btm, echo = F, echo = FALSE, message=FALSE, warning=FALSE}
edgelist_77_btm= topics_77_btm %>%
  filter(weight >= .01) %>%
  arrange(target)

sources <- edgelist_77_btm$source
targets <- edgelist_77_btm$target
node_names <- factor(unique(c(sort(unique(as.character(sources))), as.character(targets))))



groups = edgelist_77_btm %>% group_by(target) %>% top_n(1, weight)
groups = groups$source
nodes <- data.frame(name = node_names, group = c(1:num_clusters, groups), size = 8)
links <- data.frame(source = match(sources, node_names) - 1, 
                    target = match(targets, node_names) - 1, 
                    value = edgelist_77_btm$weight)
net_77_btm = forceNetwork(Links = links, Nodes = nodes, Source = "source",
             Target = "target", Value = "value", NodeID = "name",
             Group = "group", opacity = 0.9, zoom = T)
net_77_btm
```

#### White Soldiers Long Comment
```{r 78 btm, echo = F, echo = FALSE, message=FALSE, warning=FALSE}
edgelist_78_btm= topics_78_btm %>%
  filter(weight >= .01) %>%
  arrange(target)

sources <- edgelist_78_btm$source
targets <- edgelist_78_btm$target
node_names <- factor(unique(c(sort(unique(as.character(sources))), as.character(targets))))



groups = edgelist_78_btm %>% group_by(target) %>% top_n(1, weight)
groups = groups$source
nodes <- data.frame(name = node_names, group = c(1:num_clusters, groups), size = 8)
links <- data.frame(source = match(sources, node_names) - 1, 
                    target = match(targets, node_names) - 1, 
                    value = edgelist_78_btm$weight)
net_78_btm = forceNetwork(Links = links, Nodes = nodes, Source = "source",
             Target = "target", Value = "value", NodeID = "name",
             Group = "group", opacity = 0.9, zoom = T)
net_78_btm
```

```

networks in the context of networks

# Conclusion

what we learned, why it matters
